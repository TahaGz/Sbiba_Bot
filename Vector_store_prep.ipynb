{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Load and Vectorize Historical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a FAISS-based vector store for storing and retrieving FAQ answers efficiently using vector search. Here’s a breakdown of what’s happening:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS Vector Store Created (Only Answers Stored)\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load FAQ data (only answers)\n",
    "with open(\"FaQ_en.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    faq_data = json.load(f)\n",
    "\n",
    "# Extract answers only\n",
    "answers = [q[\"answer\"] for q in faq_data]  # Store only answers (no questions)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "answer_embeddings = embedding_model.embed_documents(answers)\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "answer_vectors = np.array(answer_embeddings).astype(\"float32\")\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = answer_vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(answer_vectors)\n",
    "\n",
    "# Save FAISS index & metadata\n",
    "faiss.write_index(index, \"faiss_index\")\n",
    "with open(\"faiss_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(answers, f)  # Save answers only\n",
    "\n",
    "print(\"✅ FAISS Vector Store Created (Only Answers Stored)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading and Processing FAQ Data\n",
    "- The script loads a JSON file (FaQ_en.json) that contains FAQ entries.\n",
    "- It extracts only the answers, discarding the questions. This means the retrieval will be based only on answers.\n",
    "2. Generating Embeddings for Answers\n",
    "- Uses Ollama’s nomic-embed-text model to generate embeddings.\n",
    "- Each answer is converted into a dense vector representation.\n",
    "- These embeddings are crucial for semantic search, allowing the system to find similar answers based on meaning, not just keywords.\n",
    "3. Preparing FAISS Index\n",
    "- Converts embeddings into a NumPy array (float32 format) to be used with FAISS.\n",
    "- Initializes a FAISS Index using IndexFlatL2, which performs L2 (Euclidean) distance calculations for similarity search.\n",
    "- Adds the vectors to the index, enabling fast retrieval.\n",
    "4. Saving the FAISS Index and Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Study Resources:\n",
    "- **FAISS Documentation**: https://faiss.ai/\n",
    "- **Vector Embeddings**: Study models like BERT, SentenceTransformers, OpenAI embeddings.\n",
    "- **LangChain RAG**: Learn how to use vector stores in retrieval-augmented generation.\n",
    "- **Scaling FAISS**: Learn how to use quantization (PQ, OPQ) for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 139 new entries to the FAISS vector store!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Load the FAISS index & metadata\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "index = faiss.read_index(\"faiss_index\")\n",
    "\n",
    "with open(\"faiss_metadata.pkl\", \"rb\") as f:\n",
    "    stored_answers = pickle.load(f)\n",
    "\n",
    "# Load new JSON file\n",
    "json_file_path = \"processed_sites.json\"\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    site_data = json.load(f)\n",
    "\n",
    "# Create a list to store new embeddings\n",
    "new_embeddings = []\n",
    "new_texts = []\n",
    "\n",
    "# Iterate through JSON entries and create embeddings\n",
    "for site in site_data:\n",
    "    site_name = site.get(\"site_name\", \"\")\n",
    "    location_description = site.get(\"location_description\", \"\")\n",
    "    summary = site.get(\"summary\", \"\")\n",
    "\n",
    "    # Create text representation\n",
    "    new_text = f\"{site_name}. {location_description} {summary}\"\n",
    "\n",
    "    # Generate the embedding\n",
    "    new_embedding = embedding_model.embed_query(new_text)\n",
    "\n",
    "    # Store for batch addition\n",
    "    new_embeddings.append(new_embedding)\n",
    "    new_texts.append(new_text)\n",
    "\n",
    "# Convert new embeddings to numpy array\n",
    "new_embeddings_np = np.array(new_embeddings).astype('float32')\n",
    "\n",
    "# Append new embeddings to the existing FAISS index\n",
    "index.add(new_embeddings_np)\n",
    "\n",
    "# Append new texts to metadata storage\n",
    "stored_answers.extend(new_texts)\n",
    "\n",
    "# Save the updated FAISS index\n",
    "faiss.write_index(index, \"faiss_index\")\n",
    "\n",
    "# Save the updated metadata\n",
    "with open(\"faiss_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(stored_answers, f)\n",
    "\n",
    "print(f\"Successfully added {len(new_texts)} new entries to the FAISS vector store!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adding entries to vector store from separate data source (PDF in our case treated to JSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
